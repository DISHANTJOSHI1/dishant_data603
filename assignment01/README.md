# Dishant Fapot


### Big Data with example and types
_Big Data is a collection of huge data coming from variety of online or offline sources in digital form growing exponentially. Types of Big Datas are as follows:_
- **Structured Big Data:** Data which can be stored, accessed or processed in a fixed format is a type of structured big data. For e.g., table containing strings, int or any character like a worksheet. 
- **Unstructured Big Data:** Data with unknown structure or format in unstructure big data. Image file, videos, audio, etc.
- **Semi-Structured Big Data:** This type of big data contains both the forms of the other forms of big data which visually looks like a structured but is actually unstrucutre. e.g., xml file.



###  6 ‘V’s of Big Data (define each)

_The six 'v's are as follows_
 1. Volume: Big data is a form of data whose volume is so large that it would not ﬁt on a single machine therefore specialized tools and frameworks are required to store process and analyze such data.
 2. Velocity: Velocity of data refers to how fast the data is being generated. Data generated by certain sources can arrive at very high velocities, for example, social media data or sensor data.
 3. Variety: Variety refers to the forms of the data. Big data comes in different forms such as structured, unstructured or semi-structured, including text data, image, audio, video and sensor data.
 4. Variability: Inconsistency of the data set can hamper processes to handle and manage it. For instance, sensor data quality might be inconstant
 5. Veracity: Veracity refers to quality and how accurate is the data. To extract value from the data, the data needs to be cleaned with noise data removed. 
 6. Value: Value of data refers to the usefulness of data for the intended purpose. The end goal of any big data analytics system is to extract value from the data. 


### Phases of Big Data analysis
* **Phase 1: Data Acquisition and Recording-** For big data analysis, we collect data from various sources like sensors, IoT, social media and many other digital platforms. But much of the data is not in the form we need and it needs to be filtered and compressed. We only consider data of our interest and discard rest of the data. 
* **Phase 2: Information Extraction and Cleaning-** The data we collect is huge and it contains noise which adulterate the analysis process. So we extract the data and make it in structured form. By using different data tools we clean the data for further analysis. 
* **Phase 3: Data Integration, Aggregation, and Representation-** As mentioned earlier, data is being collected from multiple source and these data needs to be integrated based on the demand which can help to reduce redundency.We use different data visualization tools like tableau, power-bi, etc. to visualiza the data and get obeservations from big data.
* **Phase 4: Query Processing, Data Modeling, and Analysis-** With the help of query, we get subset of the data. Then, we have data modelling in which we create ML model and try to make different predictions helpful in decision making in businesses. 
* **Phase 5: Interpretation-** It is important to interprete the data. Verify whether the outputs make any sense and is it answering the questions we have as a data scientist.


### Challenges in Big Data analysis
* **AChallenge 1: Heterogeneity and Incompleteness**
  *	Responsible for creating graphQL & REST APIs using NodeJS, TypeOrm, SQL Server and Typescript. 
  *	Created modules like session & login modules of a web application using microservice architecture.
  *	Trained and mentored a new team member for smooth on-boarding and replacement.
  *	Communicated effectively with supervisors regarding customer/client issues
  *	Participated in cultural activities and training sessions designed to foster rapport among colleagues. 

* **Data Analyst Intern**, Cloudstrats Technologies Private Limited, Mumbai, India      ; Nov 2020 - Apr 2021  
  *	Manifested strong multitasking skills by working part time with this company along with a full-time job at other company
  *	Worked on the technologies like Office 365, Tableau and azure Machine Learning.
  *	Handled internal projects by initiating Data Pre-Processing techniques and Visualizing Data with Tableau and reporting the same to Sr. Data Analyst.
  *	Responsible for the ‘Narad’ project that helped to contain the spread of Covid-19 in Mumbai slums. 


## PROJECTS
* **Car Selling Price Prediction and Deployment: python | scikit-learn | Flask | HTML**	[(Demo)](https://used-car-selling-price-india.herokuapp.com/)
  *	Created a fully functional web application deployed on Heroku cloud platform that predicts used cars selling price based on features like showroom price, purchasing year, engine type, etc.
  * Backend powered by machine learning model using Random Forest Regression algorithm.
  * Flask is used for integration of HTML for frontend and Machine Learning Model.

* **Election, Unemployment and Minimum Wage Relation Analysis: Jupyter Notebook | Python**	[(Github)](https://github.com/DISHANTJOSHI1/Data-Anlysis-Projects/blob/main/Project%20_3_final.ipynb)
  * Followed a step-by-step approach to extract insights from the data using python lib. like numpy, pandas, seaborn. matplotlib.
  * Analyzed relation between US election and election result’s impact on unemployment rate and minimum wages in different counties.
  * Wrangled, organized, and explored the features of datasets from various sources.
  * Prepared reports with visualizations for presentations.

* **Baltimore Crime Analysis: python | MySQL | AWS | Tableau**	[(Demo)](https://public.tableau.com/app/profile/dishant.fapot/viz/Project1_16383109555130/Story1)
  * Split the dataset into multiple tables and used AWS to build the basic data lake with S3 service and created crawlers.
  * Used AWS Athena as interactive query service to perform various operation in database.
  * Connected AWS server to visualization tool tableau to create a visualized story get insight about the data, find outliers and draw conclusions to decrease crimes in the city.



## RECOGNITION
- Secured   first   place,   “Project   problem   in   electronics   & telecommunication engineering Competition” held at RAIT, Navi Mumbai; 											Jan 2019
- Successfully organized event in technical fest of RAIT;						Oct 2018
-	Member of the Institution of Electronics and Telecommunication Engineers;  			Dec 2016 to Mar 2020

