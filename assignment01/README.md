# Dishant Fapot


### Big Data with example and types
_Big Data is a collection of huge data coming from variety of online or offline sources in digital form growing exponentially. Types of Big Datas are as follows:_
- **Structured Big Data:** Data which can be stored, accessed or processed in a fixed format is a type of structured big data. For e.g., table containing strings, int or any character like a worksheet. 
- **Unstructured Big Data:** Data with unknown structure or format in unstructure big data. Image file, videos, audio, etc.
- **Semi-Structured Big Data:** This type of big data contains both the forms of the other forms of big data which visually looks like a structured but is actually unstrucutre. e.g., xml file.



###  6 ‘V’s of Big Data (define each)

_The six 'v's are as follows_
 1. Volume: Big data is a form of data whose volume is so large that it would not ﬁt on a single machine therefore specialized tools and frameworks are required to store process and analyze such data.
 2. Velocity: Velocity of data refers to how fast the data is being generated. Data generated by certain sources can arrive at very high velocities, for example, social media data or sensor data.
 3. Variety: Variety refers to the forms of the data. Big data comes in different forms such as structured, unstructured or semi-structured, including text data, image, audio, video and sensor data.
 4. Variability: Inconsistency of the data set can hamper processes to handle and manage it. For instance, sensor data quality might be inconstant
 5. Veracity: Veracity refers to quality and how accurate is the data. To extract value from the data, the data needs to be cleaned with noise data removed. 
 6. Value: Value of data refers to the usefulness of data for the intended purpose. The end goal of any big data analytics system is to extract value from the data. 


### Phases of Big Data analysis
* **Phase 1: Data Acquisition and Recording-** For big data analysis, we collect data from various sources like sensors, IoT, social media and many other digital platforms. But much of the data is not in the form we need and it needs to be filtered and compressed. We only consider data of our interest and discard rest of the data. 
* **Phase 2: Information Extraction and Cleaning-** The data we collect is huge and it contains noise which adulterate the analysis process. So we extract the data and make it in structured form. By using different data tools we clean the data for further analysis. 
* **Phase 3: Data Integration, Aggregation, and Representation-** As mentioned earlier, data is being collected from multiple source and these data needs to be integrated based on the demand which can help to reduce redundency.We use different data visualization tools like tableau, power-bi, etc. to visualiza the data and get obeservations from big data.
* **Phase 4: Query Processing, Data Modeling, and Analysis-** With the help of query, we get subset of the data. Then, we have data modelling in which we create ML model and try to make different predictions helpful in decision making in businesses. 
* **Phase 5: Interpretation-** It is important to interprete the data. Verify whether the outputs make any sense and is it answering the questions we have as a data scientist.


### Challenges in Big Data analysis
* **Challenge 1: Heterogeneity and Incompleteness-** Algorithms for machine analysis expect homogenous data and are unable to comprehend subtlety or any other kind of small variations. More research is needed to effectively represent, access, and analyze semi-structured data.  There may still be some incompleteness and inaccuracies in the data even after data cleaning and error rectification.

* **Challenge 2: Scale-** Data volume is increasing more quickly than computing capacity.  Many expect that data will rise exponentially. and in this situation utilizing cloud computing is a viable alternative. Altering the storage subsystem might have an impact on all aspects of data processing as it can speed up or slow down the processing of big data.

* **Challenge 3: Timeliness-** Considering how time critiacal some decisions are, computing big data can sometimes take hours which is not ideal. Many of queris also take longer time to process. Hence timeliness of big data is a challenge.

* **Challenge 4: Privacy-** With big data growing exponentially it is getting more and more difficult to secure this data from red hat hackers.Big data is easy to extract based on location, time and other data attribute.

* **Challenge 5: Human Collaboration-** A big data analysis system has to accommodate input from various human specialists as well as collaborative results exploration, which is still not as efficient as it has to be.

